{
  "hash": "dab3ee38e09e87e37cb388004591c4c2",
  "result": {
    "markdown": "---\ntitle: Model assessment and variable selection\nslug: model-assessment-variable-selection\nauthor: therimalaya\ndate: 2017-03-05\ntoc: true\ntags:\n  - Statistics\n  - Modeling\n---\n\n\n\n\nWhenever we add a variable in our model, we are not only adding information but also noise that clutter the information and makes the analysis difficult. Simpler model is always better since they contain less noise and they are easy to interpret. In real life, things are not that simple. But relax, there are statistical methods that make model assessment and perform variable selection and gives optimal set of variables for us. \n\nHere, I will discuss how to compare model to know which one is better than other. This model assessment help us to select a model with few variable that can perform as good as a model with large number of variables. Here comes the idea of variable selection. I will try to explain these concepts with an example. For the example I will use `mtcars` data set which is available in R by default. Following are two well know procedure of selecting subset of variables,\n\n# Best subset method #\n\nBest subset procedure selects best regression model by running all possible subset of variables. When number of variable is large, the possible combinations of candidate subset become huge. For example, for 2 variable case ($X_1$ and $X_2$), there are 4 possible subsets -- 1 with no predictors, 2 with single predictors and 1 with both predictors. Similarly, if there are 4 variable case ($X_1, X_2, X_3$ and $X_4$), there will be 16 possible subset. In general, fitting all possible subset of large number of predictors becomes computationally intensive.\n\nOnce, all the possible model is fitted, they are compared based on some criteria. This model assessment may based on various criteria such as coefficient of determination ($R^2$), adjusted $R^2$, Mallow's CP, AIC and BIC. In R, [leaps](https://www.rdocumentation.org/packages/leaps/versions/2.1-1) package can be used for performing this operation. Lets dig into our `mtcars` example.\n\n<details>\n<summary>\n**Fitting a complete model:**\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfull.model <- lm(mpg ~ ., data = mtcars)\nsmry <- summary(full.model)\n```\n:::\n\n</summary>\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsmry\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ ., data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4506 -1.6044 -0.1196  1.2193  4.6271 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept) 12.30337   18.71788   0.657   0.5181  \ncyl         -0.11144    1.04502  -0.107   0.9161  \ndisp         0.01334    0.01786   0.747   0.4635  \nhp          -0.02148    0.02177  -0.987   0.3350  \ndrat         0.78711    1.63537   0.481   0.6353  \nwt          -3.71530    1.89441  -1.961   0.0633 .\nqsec         0.82104    0.73084   1.123   0.2739  \nvs           0.31776    2.10451   0.151   0.8814  \nam           2.52023    2.05665   1.225   0.2340  \ngear         0.65541    1.49326   0.439   0.6652  \ncarb        -0.19942    0.82875  -0.241   0.8122  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.65 on 21 degrees of freedom\nMultiple R-squared:  0.869,\tAdjusted R-squared:  0.8066 \nF-statistic: 13.93 on 10 and 21 DF,  p-value: 3.793e-07\n```\n:::\n:::\n\n</details>\n\nHere, we can see that the model has explained almost 86.9 percent of variation present in `mpg`, but non of the predictors are significant. This is a hint of having unnecessary variables that has increased model error. Using `regsubsets` function from `leaps` package, we can select a subset of predictors based on some criteria.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(leaps)\nbest.subset <-\n  regsubsets(\n    x      = mtcars[, -1],     # predictor variables\n    y      = mtcars[, 1],      # response variable (mpg)\n    nbest  = 1,                # top 1 best model\n    nvmax  = ncol(mtcars) - 1, # max. number of variable (all)\n    method = \"exhaustive\"      # search all possible subset\n  )\nbs.smry <- summary(best.subset)\n```\n:::\n\n\nWe can combine following summary output with a plot created from additional estimates to get some insight. These estimates are also found in the summary object. The output show which variables are included with a star(`*`). \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npander::pander(bs.smry$outmat)\nbs.est <- data.frame(\n  nvar   = 1:(best.subset$nvmax - 1),\n  adj.r2 = round(bs.smry$adjr2, 3),\n  cp     = round(bs.smry$cp, 3),\n  bic    = round(bs.smry$bic, 3)\n)\nbs.est <- tidyr::gather(bs.est, \"estimates\", \"value\", -nvar)\n```\n\n::: {.cell-output-display}\n---------------------------------------------------------------------------\n    &nbsp;      cyl   disp   hp   drat   wt   qsec   vs   am   gear   carb \n-------------- ----- ------ ---- ------ ---- ------ ---- ---- ------ ------\n **1 ( 1 )**                             *                                 \n\n **2 ( 1 )**     *                       *                                 \n\n **3 ( 1 )**                             *     *          *                \n\n **4 ( 1 )**                 *           *     *          *                \n\n **5 ( 1 )**           *     *           *     *          *                \n\n **6 ( 1 )**           *     *     *     *     *          *                \n\n **7 ( 1 )**           *     *     *     *     *          *     *          \n\n **8 ( 1 )**           *     *     *     *     *          *     *      *   \n\n **9 ( 1 )**           *     *     *     *     *     *    *     *      *   \n\n **10 ( 1 )**    *     *     *     *     *     *     *    *     *      *   \n---------------------------------------------------------------------------\n:::\n:::\n\n\n<details>\n<summary> We can make a plot to visualise the properties of these individual models and select a model with specific number of predictor that can give minimum BIC, or minimum CP or maximum adjusted rsquared.</summary>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\nbs.est.select <- bs.est %>%\n  group_by(estimates) %>%\n  filter(\n    (value == max(value) & estimates == \"adj.r2\") |\n    (value == min(value) & estimates != \"adj.r2\")\n  )\nassessment.plt <- ggplot(bs.est, aes(nvar, value, color = estimates)) +\n  geom_point(shape = 21, fill = \"lightgray\") +\n  geom_line() +\n  facet_wrap(~estimates, scale = 'free_y') +\n  theme(legend.position = \"top\") +\n  labs(x = \"Number of variables in the model\",\n       y = \"Value of Estimate\") +\n  scale_x_continuous(breaks = seq(0, 10, 2)) +\n  geom_point(data = bs.est.select, fill = \"red\",\n             shape = 21) +\n  geom_text(aes(label = paste0(\"nvar:\", nvar, '\\n', \"value:\", value)),\n            data = bs.est.select, \n            size = 3, hjust = 0, vjust = c(1, -1, -1),\n            color = \"black\", family = \"monospace\")\n```\n:::\n\n</details>\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/assessment.plot-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nFrom these plots, we see that with 5 variables we will obtain maximum adjusted coefficient of determination ($R^2$). Similarly, both BIC and Mallow CP will be minimum for models with only 3 predictor variables. With the help of table above, we can identify these variables. From the table, row corresponding to 3 variables, we see that the three predictors are `wt`, `qsec` and `am`. To obtain maximum adjusted $R^2$, `disp` and `hp` should be added to the previous 3 predictors.\n\nThis way, we can reduce a model to few variables optimising different assessment criteria. Let look at the fit of these reduced models:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel.3 <- lm(mpg ~ wt + qsec + am, data = mtcars)\nmodel.5 <- update(model.3, . ~ . + disp + hp)\n```\n:::\n\n\n## Summaries of the models {.tabset}\n\n### 3 Variable Model {.tab}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(model.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ wt + qsec + am, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4811 -1.5555 -0.7257  1.4110  4.6610 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   9.6178     6.9596   1.382 0.177915    \nwt           -3.9165     0.7112  -5.507 6.95e-06 ***\nqsec          1.2259     0.2887   4.247 0.000216 ***\nam            2.9358     1.4109   2.081 0.046716 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.459 on 28 degrees of freedom\nMultiple R-squared:  0.8497,\tAdjusted R-squared:  0.8336 \nF-statistic: 52.75 on 3 and 28 DF,  p-value: 1.21e-11\n```\n:::\n:::\n\n\n### 5 Variable Model {.tab}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(model.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ wt + qsec + am + disp + hp, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5399 -1.7398 -0.3196  1.1676  4.5534 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept) 14.36190    9.74079   1.474  0.15238   \nwt          -4.08433    1.19410  -3.420  0.00208 **\nqsec         1.00690    0.47543   2.118  0.04391 * \nam           3.47045    1.48578   2.336  0.02749 * \ndisp         0.01124    0.01060   1.060  0.29897   \nhp          -0.02117    0.01450  -1.460  0.15639   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.429 on 26 degrees of freedom\nMultiple R-squared:  0.8637,\tAdjusted R-squared:  0.8375 \nF-statistic: 32.96 on 5 and 26 DF,  p-value: 1.844e-10\n```\n:::\n:::\n\n\nFrom these output, it seems that although adjusted $R^2$ has increased in later model, the additional variables are not significant. we can compare these two model with an ANOVA test which compares the residual variance between these two models. We can write the hypothesis as,\n\n$H_0:$ _Model 1_ and _Model 2_ are same vs $H_1:$ _Model 1_ and _Model 2_ are different\n\nwhere, _Model 1_ and _Model 2_ represents 3 variable and 5 variable model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(model.3, model.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: mpg ~ wt + qsec + am\nModel 2: mpg ~ wt + qsec + am + disp + hp\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     28 169.29                           \n2     26 153.44  2    15.848 1.3427 0.2786\n```\n:::\n:::\n\n\nThe ANOVA result can not reject the hypothesis so claim that _Model 1_ and _Model 2_ are same. So, it is better to select the simpler model with 3 predictor variables. \n\n# Step-wise selection #\n\nWhen the number of increases, a exhaustive search of all possible subset is computationally intensive. This disadvantage can be overcome by using step-wise selection procedure. A step-wise variable selection procedure can be,\n\n**Forward Selection Procedure**\n  : In this procedure ... \n\n**Backward Elimination Procedure**\n  : Here ...\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}